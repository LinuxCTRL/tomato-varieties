#!/usr/bin/env python3
"""
Fix JSON compatibility between scraper and UI
Ensures the scraped data is in the correct format for the API/UI
"""

import json
import os
import sys

def check_json_compatibility():
    """Check if the JSON file is compatible with the UI"""

    print("ğŸ” Checking JSON compatibility...")

    # Check if the main file exists
    if not os.path.exists('tomato_varieties.json'):
        print("âŒ tomato_varieties.json not found!")

        # Check for alternative files
        alternatives = [
            'tomato_varieties_multithreaded.json',
            'tomato_varieties_beautiful.json'
        ]

        for alt in alternatives:
            if os.path.exists(alt):
                print(f"âœ… Found {alt}, copying to tomato_varieties.json...")
                with open(alt, 'r', encoding='utf-8') as src:
                    data = json.load(src)
                with open('tomato_varieties.json', 'w', encoding='utf-8') as dst:
                    json.dump(data, dst, indent=2, ensure_ascii=False)
                print("âœ… File copied successfully!")
                break
        else:
            print("âŒ No compatible JSON files found. Please run the scraper first.")
            return False

    # Validate the JSON structure
    try:
        with open('tomato_varieties.json', 'r', encoding='utf-8') as f:
            data = json.load(f)

        print("âœ… JSON file loaded successfully!")

        # Check required fields
        required_fields = ['varieties', 'total_count', 'scraped_at']
        missing_fields = [field for field in required_fields if field not in data]

        if missing_fields:
            print(f"âš ï¸  Missing fields: {missing_fields}")
            return False

        # Check varieties structure
        if not data['varieties']:
            print("âš ï¸  No varieties found in data")
            return False

        # Check sample variety structure
        sample_variety = data['varieties'][0]
        variety_required_fields = ['name', 'url', 'slug']
        missing_variety_fields = [field for field in variety_required_fields if field not in sample_variety]

        if missing_variety_fields:
            print(f"âš ï¸  Missing variety fields: {missing_variety_fields}")
            return False

        # Print summary
        print(f"ğŸ“Š Data Summary:")
        print(f"   â€¢ Total varieties: {data['total_count']}")
        print(f"   â€¢ Scraped at: {data['scraped_at']}")
        print(f"   â€¢ Source: {data.get('source', 'Unknown')}")

        if 'scraping_stats' in data:
            stats = data['scraping_stats']
            print(f"   â€¢ Scraping time: {stats.get('total_time_seconds', 'Unknown')}s")
            print(f"   â€¢ Workers used: {stats.get('workers_used', 'Unknown')}")

        print("âœ… JSON structure is compatible with the UI!")
        return True

    except json.JSONDecodeError as e:
        print(f"âŒ JSON parsing error: {e}")
        return False
    except Exception as e:
        print(f"âŒ Error checking JSON: {e}")
        return False

def test_api_compatibility():
    """Test if the API can load the data"""

    print("\nğŸ§ª Testing API compatibility...")

    try:
        # Simulate API loading
        import sys
        import os

        # Add current directory to path
        sys.path.insert(0, os.getcwd())

        # Try to import and test the API
        from backend.api import load_tomato_data

        result = load_tomato_data()

        if 'error' in result:
            print(f"âŒ API loading failed: {result['error']}")
            return False

        print("âœ… API can load the data successfully!")
        print(f"   â€¢ Loaded {len(result.get('varieties', []))} varieties")
        return True

    except ImportError:
        print("âš ï¸  Could not import API module (this is okay if running standalone)")
        return True
    except Exception as e:
        print(f"âŒ API test failed: {e}")
        return False

def main():
    """Main function"""

    print("ğŸ… JSON Compatibility Checker")
    print("=" * 40)

    # Check JSON compatibility
    json_ok = check_json_compatibility()

    if json_ok:
        # Test API compatibility
        api_ok = test_api_compatibility()

        if json_ok and api_ok:
            print("\nğŸ‰ Everything looks good!")
            print("âœ… Your scraper data is compatible with the UI")
            print("ğŸš€ You can now start the servers:")
            print("   1. python api.py")
            print("   2. node server.js")
            print("   3. Open http://localhost:3000")
        else:
            print("\nâš ï¸  Some issues found, but JSON structure is okay")
    else:
        print("\nâŒ JSON compatibility issues found")
        print("ğŸ’¡ Try running the scraper again:")
        print("   python scraper.py")

if __name__ == "__main__":
    main()
